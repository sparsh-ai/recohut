{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "3.Item-basedCollaborativeFiltering.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtfpuFYJgCQ2"
      },
      "source": [
        "# CF Part 3 - Item-based method\n",
        "> Collaborative Filtering on MovieLens Latest-small Part 3 - Finding recommendations using memory based item-item similarity method\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [movie, collaborative]\n",
        "- image:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4-1x60KgCQ3"
      },
      "source": [
        "## Idea\n",
        "Let $u$ be the active user and $i$ the referenced item\n",
        "1. If $u$ liked items similar to $i$, he will probably like item $i$.\n",
        "2. If he hated or disliked items similar to $i$, he will also hate item $i$.\n",
        "\n",
        "The idea is therefore to look at how an active user $u$ rated items similar to $i$ to know how he would have rated item $i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXuDy5JLgCQ4"
      },
      "source": [
        "## Advantages over user-based CF\n",
        "\n",
        "1. <b> Stability </b> : Items ratings are more stable than users ratings. New ratings on items are unlikely to significantly change the similarity between two items, particularly when the items have many ratings <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>. \n",
        "2. <b> Scalability </b> : with stable item's ratings, it is reasonable to pre-compute similarities between items in an item-item similarity matrix (similarity between items can be computed offline). This will reduce the scalability concern of the algorithm. <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\">(Sarwar <i>et al.</i> 2001)</a>, <a href=\"https://dl.acm.org/doi/10.1561/1100000009\">(Michael D. Ekstrand, <i>et al.</i> 2011)</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbVv7UzQgCQ5"
      },
      "source": [
        "## Algorithm : item-to-item collaborative filtering\n",
        "\n",
        "The algorithm that defines item-based CF is described as follow <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.449.1171&rep=rep1&type=pdf\">(B. Sarwar et al. 2001)</a><a href=\"https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.554.1671&rep=rep1&type=pdf\">(George Karypis 2001)</a> :\n",
        "\n",
        "<ol>\n",
        "    <li>\n",
        "        First identify the $k$ most similar items for each item in the catalogue and record the corresponding similarities. To compute similarity between two items we can user the <i>Adjusted Cosine Similarity</i> that has proven to be more efficient than the basic <i>Cosine similarity measure</i> used for user-based collaborative as described in <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.449.1171&rep=rep1&type=pdf\">(B. Sarwar et al. 2001)</a>. The Adjusted Cosine distance between two items $i$ and $j$ is computed as follow\n",
        "\n",
        "\\begin{equation}\n",
        " w_{i,j}= \\frac{\\sum_{u\\in U}(r_{u,i}-\\bar{r}_u)(r_{u,j}-\\bar{r}_u)}{\\sqrt{\\sum_{u\\in U} (r_{u,i}-\\bar{r}_u)^2}\\sqrt{\\sum_{u\\in U} (r_{u,j}-\\bar{r}_u)^2}}\n",
        "\\end{equation}\n",
        "\n",
        "$w_{i,j}$ is the degree of similarity between items $i$ and $j$. This term is computed for all users $u\\in U$, where $U$ is the set of users that rated both items $i$ and $j$. Let's denote by $S^{(i)}$ the set of the $k$ most similar items to item $i$.\n",
        "    </li>    \n",
        "    <li> To produce top-N recommendations for a given user $u$ that has already purchased a set $I_u$ of items, do the following :\n",
        "<ul>\n",
        "    <li> Find the set $C$ of candidate items by taking the union of all $S^{(i)}, \\forall i\\in I_u$ and removing each of the items in the set $I_u$.\n",
        "\\begin{equation}\n",
        " C = \\bigcup_{i\\in I_u}\\{S^{(i)}\\}\\smallsetminus I_u\n",
        "\\end{equation}\n",
        "    </li>\n",
        "    <li>\n",
        "        $\\forall c\\in C$, compute similarity between c and the set $I_u$ as follows:\n",
        "\\begin{equation}\n",
        " w_{c,I_u} = \\sum_{i\\in I_u} w_{c,i}, \\forall c \\in C\n",
        "\\end{equation}\n",
        "    </li>\n",
        "    <li>\n",
        "        Sort items in $C$ in decreasing order of $w_{c,I_u}, \\forall c \\in C$, and return the first $N$ items as the Top-N recommendation list.\n",
        "    </li>\n",
        "</ul>    \n",
        "    </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX6Nj-yWgCQ9"
      },
      "source": [
        "Before returning the first $N$ items as top-N recommendation list, we can make predictions about what user $u$ would have given to each items in the top-N recommendation list, rearrange the list in descending order of predicted ratings and return the rearranged list as the final recommendation list. Rating prediction for item-based CF is given by the following formular <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.449.1171&rep=rep1&type=pdf\">(B. Sarwar et al. 2001)</a>:\n",
        "\n",
        "\\begin{equation}\n",
        " \\hat{r}_{u,i}=\\frac{\\sum_{i\\in S^{(i)}}r_{u,j}\\cdot w_{i,j}}{\\sum_{j\\in S^{(i)}}|w_{i,j}|}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtMl7OD2gCRA"
      },
      "source": [
        "### Import useful requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_n9x9VtgCRB"
      },
      "source": [
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kubu9WOjgCRC"
      },
      "source": [
        "### Import requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNHO40yIgCRE"
      },
      "source": [
        "```\n",
        "matplotlib==3.2.2\n",
        "numpy==1.19.2\n",
        "pandas==1.0.5\n",
        "python==3.7\n",
        "scikit-learn==0.24.1\n",
        "scikit-surprise==1.1.1\n",
        "scipy==1.6.2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGvRWO6agCRF"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "from recsys.datasets import ml1m, ml100k\n",
        "from recsys.preprocessing import ids_encoder\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB4zW0-PgCRI"
      },
      "source": [
        "### Load ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6y4doBGgCRL"
      },
      "source": [
        "ratings, movies = ml100k.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkD5QbH6gCRR"
      },
      "source": [
        "### userids and itemids encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ0TGn0MgCRT"
      },
      "source": [
        "# create the encoder\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1fMwy11gCRT"
      },
      "source": [
        "Let's implements the item-based collaborative filtering algorithm described above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ua8DZMGgCRW"
      },
      "source": [
        "### Step 1. Find similarities for each of the items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4S1UAsbgCRW"
      },
      "source": [
        "To compute similarity between two items $i$ and $j$, we need to :\n",
        "\n",
        "1. find all users who rated both of them,\n",
        "2. Normalize their ratings on items $i$ and $j$\n",
        "3. Apply the cosine metric to the normalized ratings to compute similarity between $i$ and $j$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU1VxSZEgCRX"
      },
      "source": [
        "Function ```normalize()``` process the rating dataframe to normalize ratings of all users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2AB5WB1gCRk"
      },
      "source": [
        "def normalize():\n",
        "    # compute mean rating for each user\n",
        "    mean = ratings.groupby(by='userid', as_index=False)['rating'].mean()\n",
        "    norm_ratings = pd.merge(ratings, mean, suffixes=('','_mean'), on='userid')\n",
        "    \n",
        "    # normalize each rating by substracting the mean rating of the corresponding user\n",
        "    norm_ratings['norm_rating'] = norm_ratings['rating'] - norm_ratings['rating_mean']\n",
        "    return mean.to_numpy()[:, 1], norm_ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvSY6uTJgCRl",
        "outputId": "9db74a55-2839-4b24-f513-c1ca0b50a258"
      },
      "source": [
        "mean, norm_ratings = normalize()\n",
        "np_ratings = norm_ratings.to_numpy()\n",
        "norm_ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>itemid</th>\n",
              "      <th>rating</th>\n",
              "      <th>rating_mean</th>\n",
              "      <th>norm_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3.610294</td>\n",
              "      <td>1.389706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3.610294</td>\n",
              "      <td>-0.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3.610294</td>\n",
              "      <td>0.389706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.610294</td>\n",
              "      <td>-0.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3.610294</td>\n",
              "      <td>-0.610294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userid  itemid  rating  rating_mean  norm_rating\n",
              "0       0       0       5     3.610294     1.389706\n",
              "1       0       1       3     3.610294    -0.610294\n",
              "2       0       2       4     3.610294     0.389706\n",
              "3       0       3       3     3.610294    -0.610294\n",
              "4       0       4       3     3.610294    -0.610294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj4OKJoGgCRn"
      },
      "source": [
        "now that each rating has been normalized, we can represent each item by a vector of its normalized ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We0b8U5dgCRp"
      },
      "source": [
        "def item_representation(ratings):    \n",
        "    return csr_matrix(\n",
        "        pd.crosstab(ratings.itemid, ratings.userid, ratings.norm_rating, aggfunc=sum).fillna(0).values\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDM8olmSgCRr"
      },
      "source": [
        "R = item_representation(norm_ratings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf_gosbogCRs"
      },
      "source": [
        "Let's build and fit our $k$-NN model using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mohrtd9gCRu"
      },
      "source": [
        "def create_model(rating_matrix, k=20, metric=\"cosine\"):\n",
        "    \"\"\"\n",
        "    :param R : numpy array of item representations\n",
        "    :param k : number of nearest neighbors to return    \n",
        "    :return model : our knn model\n",
        "    \"\"\"    \n",
        "    model = NearestNeighbors(metric=metric, n_neighbors=k+1, algorithm='brute')\n",
        "    model.fit(rating_matrix)    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKxTLWqVgCR0"
      },
      "source": [
        "#### Similarities computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IedNhvlUgCR1"
      },
      "source": [
        "Similarities between items can be measured with the *Cosine* or *Eucliedian* distance. The ***NearestNeighbors*** class from the sklearn library simplifies the computation of neighbors. We just need to specify the metric (e.g. cosine or euclidian) that will be used to compute similarities.\n",
        "\n",
        "The above method, ```create_model```, creates the kNN model and the following ```nearest_neighbors``` method uses the created model to kNN items. It returns nearest neighbors as well as similarities measures for each items.\n",
        "\n",
        "```nearest_neighbors``` returns :\n",
        "- ```similarities``` : numpy array of shape $(n,k)$\n",
        "- ```neighbors``` : numpy array of shape $(n,k)$\n",
        "\n",
        "where $n$ is the total number of items and $k$ is the number of neighbors to return, specified when creating the kNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7rKoadUgCR1"
      },
      "source": [
        "def nearest_neighbors(rating_matrix, model):\n",
        "    \"\"\"\n",
        "    compute the top n similar items for each item.    \n",
        "    :param rating_matrix : items representations\n",
        "    :param model : nearest neighbors model    \n",
        "    :return similarities, neighbors\n",
        "    \"\"\"    \n",
        "    similarities, neighbors = model.kneighbors(rating_matrix)    \n",
        "    return similarities[:,1:], neighbors[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqXOnJplgCR9"
      },
      "source": [
        "#### Ajusted Cosine Similarity\n",
        "In the context of item-based collaborative filtering, the adjusted cosine similarity has shown to be more efficient that the cosine or the euclidian distance. Here is the formular to compute the adjusted cosine weight between two items $i$ and $j$ :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kl-hZQjgCR-"
      },
      "source": [
        "\\begin{equation}\n",
        " w_{i,j}= \\frac{\\sum_{u\\in U}(r_{u,i}-\\bar{r}_u)(r_{u,j}-\\bar{r}_u)}{\\sqrt{\\sum_{u\\in U} (r_{u,i}-\\bar{r}_u)^2}\\sqrt{\\sum_{u\\in U} (r_{u,j}-\\bar{r}_u)^2}}.\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p0_b_FtgCR_"
      },
      "source": [
        "This term is computed for all users $u\\in U$, where $U$ is the set of users that rated both items $i$ and $j$. Since the *sklearn* library do not directly implement the adjusted cosine similarity metric, we will implement it with the method ```adjusted_cosine```, with some helper function :\n",
        "\n",
        "- ```save_similarities``` : since the computation of the adjusted cosine similarity is time consuming, around 5 mins for the ml100k dataset, we use this method to save the computed similarities for lated usage.\n",
        "- ```load_similarities``` : load the saved similarities\n",
        "- ```cosine``` : cosine distance between two vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-2fZQhdgCR_"
      },
      "source": [
        "def save_similarities(similarities, neighbors, dataset_name):    \n",
        "    base_dir = 'recsys/weights/item2item'\n",
        "    save_dir = os.path.join(base_dir, dataset_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)    \n",
        "    similarities_file_name = os.path.join(save_dir, 'similarities.npy')\n",
        "    neighbors_file_name = os.path.join(save_dir, 'neighbors.npy')    \n",
        "    try:\n",
        "        np.save(similarities_file_name, similarities)\n",
        "        np.save(neighbors_file_name, neighbors)        \n",
        "    except ValueError as error:\n",
        "        print(f\"An error occured when saving similarities, due to : \\n ValueError : {error}\")\n",
        "\n",
        "        \n",
        "def load_similarities(dataset_name, k=20):\n",
        "    base_dir = 'recsys/weights/item2item'\n",
        "    save_dir = os.path.join(base_dir, dataset_name)    \n",
        "    similiraties_file = os.path.join(save_dir, 'similarities.npy')\n",
        "    neighbors_file = os.path.join(save_dir, 'neighbors.npy')    \n",
        "    similarities = np.load(similiraties_file)\n",
        "    neighbors = np.load(neighbors_file)    \n",
        "    return similarities[:,:k], neighbors[:,:k]\n",
        "\n",
        "\n",
        "def cosine(x, y):\n",
        "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
        "\n",
        "\n",
        "def adjusted_cosine(np_ratings, nb_items, dataset_name):\n",
        "    similarities = np.zeros(shape=(nb_items, nb_items))\n",
        "    similarities.fill(-1)\n",
        "    \n",
        "    def _progress(count):\n",
        "        sys.stdout.write('\\rComputing similarities. Progress status : %.1f%%' % (float(count / nb_items)*100.0))\n",
        "        sys.stdout.flush()\n",
        "        \n",
        "    items = sorted(ratings.itemid.unique())    \n",
        "    for i in items[:-1]:\n",
        "        for j in items[i+1:]:            \n",
        "            scores = np_ratings[(np_ratings[:, 1] == i) | (np_ratings[:, 1] == j), :]\n",
        "            vals, count = np.unique(scores[:,0], return_counts = True)\n",
        "            scores = scores[np.isin(scores[:,0], vals[count > 1]),:]\n",
        "\n",
        "            if scores.shape[0] > 2:\n",
        "                x = scores[scores[:, 1].astype('int') == i, 4]\n",
        "                y = scores[scores[:, 1].astype('int') == j, 4]\n",
        "                w = cosine(x, y)\n",
        "\n",
        "                similarities[i, j] = w\n",
        "                similarities[j, i] = w\n",
        "        _progress(i)\n",
        "    _progress(nb_items)\n",
        "    \n",
        "    # get neighbors by their neighbors in decreasing order of similarities\n",
        "    neighbors = np.flip(np.argsort(similarities), axis=1)\n",
        "    \n",
        "    # sort similarities in decreasing order\n",
        "    similarities = np.flip(np.sort(similarities), axis=1)\n",
        "    \n",
        "    # save similarities to disk\n",
        "    save_similarities(similarities, neighbors, dataset_name=dataset_name) \n",
        "    \n",
        "    return similarities, neighbors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN9pqKGvgCSC"
      },
      "source": [
        "now, we can call the ```adjusted_cosine``` function to compute and save items similarities and neighbors based on the adjusted cosine metric. \n",
        "\n",
        "uncomment the two lines of the following cell to compute the adjusted cosine between all items. As we have already run the next cell before, we will just load the precomputed similarities for further use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WruBFbgCgCSD"
      },
      "source": [
        "# nb_items = ratings.itemid.nunique()\n",
        "# similarities, neighbors = adjusted_cosine(np_ratings, nb_items=nb_items, dataset_name='ml100k')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbGrGnYngCSE"
      },
      "source": [
        "Among the following similarity metrics, choose the one you wish to use for the item-based collaborative filtering :\n",
        "\n",
        "- **euclidian** or **cosine** : choose *euclidian* or *cosine* to initialise the similarity model through the sklearn library.\n",
        "- **adjusted_cosine** : choose the *adjusted_cosine* metric to load similarities computed and saved through the ```adjusted_cosine``` function.\n",
        "\n",
        "In this case, we will use the *adjusted_cosine* metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uExs3jYNgCSF"
      },
      "source": [
        "# metric : choose among [cosine, euclidean, adjusted_cosine]\n",
        "\n",
        "metric = 'adjusted_cosine'\n",
        "\n",
        "if metric == 'adjusted_cosine':\n",
        "    similarities, neighbors = load_similarities('ml100k')\n",
        "else:\n",
        "    model = create_model(R, k=21, metric=metric)\n",
        "    similarities, neighbors = nearest_neighbors(R, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W9M6LBugCSG",
        "outputId": "b5e168ec-5e3b-463f-dead-3c7cfb5b63c1"
      },
      "source": [
        "print('neighbors shape : ', neighbors.shape)\n",
        "print('similarities shape : ', similarities.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neighbors shape :  (1682, 20)\n",
            "similarities shape :  (1682, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YmwE7i-gCSH"
      },
      "source": [
        "```neighbors``` and ```similarities``` are numpy array, were each entries are list of 20 neighbors with their corresponding similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw0wUfpFgCSH"
      },
      "source": [
        "### Step 2. Top N recommendation for a given user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTr4UYq5gCSI"
      },
      "source": [
        "Top-N recommendations are made for example for a user $u$ who has already rated a set of items $I_u$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX9rNRwygCSI"
      },
      "source": [
        "#### 2.a- Finding candidate items\n",
        "\n",
        "To find candidate items for user $u$, we need to :\n",
        "\n",
        "1. Find the set $I_u$ of items already rated by user $u$,\n",
        "2. Take the union of similar items as $C$ for all items in $I_u$\n",
        "3. exclude from the set $C$ all items in $I_u$, to avoid recommend to a user items he has already purchased.\n",
        "\n",
        "These are done in function ```candidate_items()```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yGkVKPLgCSJ"
      },
      "source": [
        "def candidate_items(userid):\n",
        "    \"\"\"\n",
        "    :param userid : user id for which we wish to find candidate items    \n",
        "    :return : I_u, candidates\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Finding the set I_u of items already rated by user userid\n",
        "    I_u = np_ratings[np_ratings[:, 0] == userid]\n",
        "    I_u = I_u[:, 1].astype('int')\n",
        "    \n",
        "    # 2. Taking the union of similar items for all items in I_u to form the set of candidate items\n",
        "    c = set()\n",
        "        \n",
        "    for iid in I_u:    \n",
        "        # add the neighbors of item iid in the set of candidate items\n",
        "        c.update(neighbors[iid])\n",
        "        \n",
        "    c = list(c)\n",
        "    # 3. exclude from the set C all items in I_u.\n",
        "    candidates = np.setdiff1d(c, I_u, assume_unique=True)\n",
        "    \n",
        "    return I_u, candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTBHlimngCSJ"
      },
      "source": [
        "test_user = uencoder.transform([1])[0]\n",
        "i_u, u_candidates = candidate_items(test_user)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_W5DaZPgCSK",
        "outputId": "ed9a7e14-9476-4a73-d0d1-44ffefd3ce8b"
      },
      "source": [
        "print('number of items purchased by user 1 : ', len(i_u))\n",
        "print('number of candidate items for user 1 : ', len(u_candidates))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of items purchased by user 1 :  272\n",
            "number of candidate items for user 1 :  893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPv4qL8ngCSK"
      },
      "source": [
        "#### 2.b- Find similarity between each candidate item and the set $I_u$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2m3P3iBgCSL"
      },
      "source": [
        "def similarity_with_Iu(c, I_u):\n",
        "    \"\"\"\n",
        "    compute similarity between an item c and a set of items I_u. For each item i in I_u, get similarity between \n",
        "    i and c, if c exists in the set of items similar to itemid.    \n",
        "    :param c : itemid of a candidate item\n",
        "    :param I_u : set of items already purchased by a given user    \n",
        "    :return w : similarity between c and I_u\n",
        "    \"\"\"\n",
        "    w = 0    \n",
        "    for iid in I_u :        \n",
        "        # get similarity between itemid and c, if c is one of the k nearest neighbors of itemid\n",
        "        if c in neighbors[iid] :\n",
        "            w = w + similarities[iid, neighbors[iid] == c][0]    \n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ss05vFdgCSL"
      },
      "source": [
        "#### 2.c- Rank candidate items according to their similarities to $I_u$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LpqLQ_7gCSM"
      },
      "source": [
        "def rank_candidates(candidates, I_u):\n",
        "    \"\"\"\n",
        "    rank candidate items according to their similarities with i_u    \n",
        "    :param candidates : list of candidate items\n",
        "    :param I_u : list of items purchased by the user    \n",
        "    :return ranked_candidates : dataframe of candidate items, ranked in descending order of similarities with I_u\n",
        "    \"\"\"\n",
        "    \n",
        "    # list of candidate items mapped to their corresponding similarities to I_u\n",
        "    sims = [similarity_with_Iu(c, I_u) for c in candidates]\n",
        "    candidates = iencoder.inverse_transform(candidates)    \n",
        "    mapping = list(zip(candidates, sims))\n",
        "    \n",
        "    ranked_candidates = sorted(mapping, key=lambda couple:couple[1], reverse=True)    \n",
        "    return ranked_candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0SkRTn9gCSM"
      },
      "source": [
        "## Putting all together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z5-lW7agCSN"
      },
      "source": [
        "Now that we defined all functions necessary to build our item to item top-N recommendation, let's define function ```item2item_topN()``` that makes top-$N$ recommendations for a given user "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRbF7MvlgCSO"
      },
      "source": [
        "def topn_recommendation(userid, N=30):\n",
        "    \"\"\"\n",
        "    Produce top-N recommendation for a given user    \n",
        "    :param userid : user for which we produce top-N recommendation\n",
        "    :param n : length of the top-N recommendation list    \n",
        "    :return topn\n",
        "    \"\"\"\n",
        "    # find candidate items\n",
        "    I_u, candidates = candidate_items(userid)\n",
        "    \n",
        "    # rank candidate items according to their similarities with I_u\n",
        "    ranked_candidates = rank_candidates(candidates, I_u)\n",
        "    \n",
        "    # get the first N row of ranked_candidates to build the top N recommendation list\n",
        "    topn = pd.DataFrame(ranked_candidates[:N], columns=['itemid','similarity_with_Iu'])    \n",
        "    topn = pd.merge(topn, movies, on='itemid', how='inner')    \n",
        "    return topn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41QHU6uYgCSO",
        "outputId": "285da05a-20ea-4369-8ab7-19840a3dc41e"
      },
      "source": [
        "topn_recommendation(test_user)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>similarity_with_Iu</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1356</td>\n",
              "      <td>52.867173</td>\n",
              "      <td>Ed's Next Move (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1189</td>\n",
              "      <td>50.362199</td>\n",
              "      <td>Prefontaine (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1516</td>\n",
              "      <td>31.133267</td>\n",
              "      <td>Wedding Gift, The (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1550</td>\n",
              "      <td>31.031738</td>\n",
              "      <td>Destiny Turns on the Radio (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1554</td>\n",
              "      <td>27.364494</td>\n",
              "      <td>Safe Passage (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1600</td>\n",
              "      <td>27.287712</td>\n",
              "      <td>Guantanamera (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1223</td>\n",
              "      <td>26.631850</td>\n",
              "      <td>King of the Hill (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1388</td>\n",
              "      <td>26.624397</td>\n",
              "      <td>Gabbeh (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>766</td>\n",
              "      <td>26.590175</td>\n",
              "      <td>Man of the Year (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>691</td>\n",
              "      <td>26.461802</td>\n",
              "      <td>Dark City (1998)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1378</td>\n",
              "      <td>25.787842</td>\n",
              "      <td>Rhyme &amp; Reason (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1664</td>\n",
              "      <td>25.327445</td>\n",
              "      <td>8 Heads in a Duffel Bag (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1261</td>\n",
              "      <td>24.785660</td>\n",
              "      <td>Run of the Country, The (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1123</td>\n",
              "      <td>24.524028</td>\n",
              "      <td>Last Time I Saw Paris, The (1954)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1538</td>\n",
              "      <td>24.492453</td>\n",
              "      <td>All Over Me (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1485</td>\n",
              "      <td>24.345312</td>\n",
              "      <td>Colonel Chabert, Le (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1450</td>\n",
              "      <td>24.262120</td>\n",
              "      <td>Golden Earrings (1947)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>909</td>\n",
              "      <td>23.357301</td>\n",
              "      <td>Dangerous Beauty (1998)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>359</td>\n",
              "      <td>22.973658</td>\n",
              "      <td>Assignment, The (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1369</td>\n",
              "      <td>22.710078</td>\n",
              "      <td>Forbidden Christ, The (Cristo proibito, Il) (1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1506</td>\n",
              "      <td>22.325504</td>\n",
              "      <td>Nelly &amp; Monsieur Arnaud (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1537</td>\n",
              "      <td>22.061914</td>\n",
              "      <td>Cosi (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1474</td>\n",
              "      <td>21.877034</td>\n",
              "      <td>Nina Takes a Lover (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1467</td>\n",
              "      <td>21.861203</td>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1255</td>\n",
              "      <td>21.750924</td>\n",
              "      <td>Broken English (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1499</td>\n",
              "      <td>21.529748</td>\n",
              "      <td>Grosse Fatigue (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1466</td>\n",
              "      <td>21.063269</td>\n",
              "      <td>Margaret's Museum (1995)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1448</td>\n",
              "      <td>20.846909</td>\n",
              "      <td>My Favorite Season (1993)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>927</td>\n",
              "      <td>20.730153</td>\n",
              "      <td>Flower of My Secret, The (Flor de mi secreto, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1375</td>\n",
              "      <td>20.627152</td>\n",
              "      <td>Cement Garden, The (1993)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    itemid  similarity_with_Iu  \\\n",
              "0     1356           52.867173   \n",
              "1     1189           50.362199   \n",
              "2     1516           31.133267   \n",
              "3     1550           31.031738   \n",
              "4     1554           27.364494   \n",
              "5     1600           27.287712   \n",
              "6     1223           26.631850   \n",
              "7     1388           26.624397   \n",
              "8      766           26.590175   \n",
              "9      691           26.461802   \n",
              "10    1378           25.787842   \n",
              "11    1664           25.327445   \n",
              "12    1261           24.785660   \n",
              "13    1123           24.524028   \n",
              "14    1538           24.492453   \n",
              "15    1485           24.345312   \n",
              "16    1450           24.262120   \n",
              "17     909           23.357301   \n",
              "18     359           22.973658   \n",
              "19    1369           22.710078   \n",
              "20    1506           22.325504   \n",
              "21    1537           22.061914   \n",
              "22    1474           21.877034   \n",
              "23    1467           21.861203   \n",
              "24    1255           21.750924   \n",
              "25    1499           21.529748   \n",
              "26    1466           21.063269   \n",
              "27    1448           20.846909   \n",
              "28     927           20.730153   \n",
              "29    1375           20.627152   \n",
              "\n",
              "                                                title  \n",
              "0                               Ed's Next Move (1996)  \n",
              "1                                  Prefontaine (1997)  \n",
              "2                            Wedding Gift, The (1994)  \n",
              "3                   Destiny Turns on the Radio (1995)  \n",
              "4                                 Safe Passage (1994)  \n",
              "5                                 Guantanamera (1994)  \n",
              "6                             King of the Hill (1993)  \n",
              "7                                       Gabbeh (1996)  \n",
              "8                              Man of the Year (1995)  \n",
              "9                                    Dark City (1998)  \n",
              "10                              Rhyme & Reason (1997)  \n",
              "11                     8 Heads in a Duffel Bag (1997)  \n",
              "12                     Run of the Country, The (1995)  \n",
              "13                  Last Time I Saw Paris, The (1954)  \n",
              "14                                 All Over Me (1997)  \n",
              "15                         Colonel Chabert, Le (1994)  \n",
              "16                             Golden Earrings (1947)  \n",
              "17                            Dangerous Beauty (1998)  \n",
              "18                             Assignment, The (1997)  \n",
              "19  Forbidden Christ, The (Cristo proibito, Il) (1...  \n",
              "20                     Nelly & Monsieur Arnaud (1995)  \n",
              "21                                        Cosi (1996)  \n",
              "22                          Nina Takes a Lover (1994)  \n",
              "23               Saint of Fort Washington, The (1993)  \n",
              "24                              Broken English (1996)  \n",
              "25                              Grosse Fatigue (1994)  \n",
              "26                           Margaret's Museum (1995)  \n",
              "27                          My Favorite Season (1993)  \n",
              "28  Flower of My Secret, The (Flor de mi secreto, ...  \n",
              "29                          Cement Garden, The (1993)  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx889wLKgCSO"
      },
      "source": [
        "This dataframe represents the top N recommendation list a user. These items are sorted in decreasing order of similarities with $I_u$.\n",
        "\n",
        "**Observation** : The recommended items are the most similar to the set $I_u$ of items already purchased by the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG55R4isgCSP"
      },
      "source": [
        "## Top N recommendation with predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubJMamVLgCSP"
      },
      "source": [
        "Before recommending the previous list to the user, we can go further and predict the ratings the user would have given to each of these items, sort them in descending order of prediction and return the reordered list as the new top N recommendation list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzrrNHgmgCSP"
      },
      "source": [
        "### Rating prediction\n",
        "\n",
        "As stated earlier, the predicted rating $\\hat{r}_{u,i}$ for a given user $u$ on an item $i$ is obtained by aggregating ratings given by $u$ on items similar to $i$ as follows:\n",
        "\n",
        "\\begin{equation}\n",
        " \\hat{r}_{u,i}=\\frac{\\sum_{j\\in S^{(i)}}r_{u,j}\\cdot w_{i,j}}{\\sum_{j\\in S^{(i)}}|w_{i,j}|}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYdz_sQLgCSQ"
      },
      "source": [
        "def predict(userid, itemid):\n",
        "    \"\"\"\n",
        "    Make rating prediction for user userid on item itemid    \n",
        "    :param userid : id of the active user\n",
        "    :param itemid : id of the item for which we are making prediction        \n",
        "    :return r_hat : predicted rating\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get items similar to item itemid with their corresponding similarities\n",
        "    item_neighbors = neighbors[itemid]\n",
        "    item_similarities = similarities[itemid]\n",
        "    \n",
        "    # get ratings of user with id userid\n",
        "    uratings = np_ratings[np_ratings[:, 0].astype('int') == userid]\n",
        "    \n",
        "    # similar items rated by item the user of i\n",
        "    siru = uratings[np.isin(uratings[:, 1], item_neighbors)]\n",
        "    scores = siru[:, 2]\n",
        "    indexes = [np.where(item_neighbors == iid)[0][0] for iid in siru[:,1].astype('int')]    \n",
        "    sims = item_similarities[indexes]\n",
        "    \n",
        "    dot = np.dot(scores, sims)\n",
        "    som = np.sum(np.abs(sims))\n",
        "\n",
        "    if dot == 0 or som == 0:\n",
        "        return mean[userid]\n",
        "    \n",
        "    return dot / som"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D6-DlSbgCSQ"
      },
      "source": [
        "Now let's use our ```predict()``` function to predict what ratings the user would have given to the previous top-$N$ list and return the reorganised list (in decreasing order of predictions) as the new top-$N$ list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZXqc221gCSQ"
      },
      "source": [
        "def topn_prediction(userid):\n",
        "    \"\"\"\n",
        "    :param userid : id of the active user    \n",
        "    :return topn : initial topN recommendations returned by the function item2item_topN\n",
        "    :return topn_predict : topN recommendations reordered according to rating predictions\n",
        "    \"\"\"\n",
        "    # make top N recommendation for the active user\n",
        "    topn = topn_recommendation(userid)\n",
        "    \n",
        "    # get list of items of the top N list\n",
        "    itemids = topn.itemid.to_list()\n",
        "    \n",
        "    predictions = []\n",
        "    \n",
        "    # make prediction for each item in the top N list\n",
        "    for itemid in itemids:\n",
        "        r = predict(userid, itemid)\n",
        "        \n",
        "        predictions.append((itemid,r))\n",
        "    \n",
        "    predictions = pd.DataFrame(predictions, columns=['itemid','prediction'])\n",
        "    \n",
        "    # merge the predictions to topN_list and rearrange the list according to predictions\n",
        "    topn_predict = pd.merge(topn, predictions, on='itemid', how='inner')\n",
        "    topn_predict = topn_predict.sort_values(by=['prediction'], ascending=False)\n",
        "    \n",
        "    return topn, topn_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f89U3bEegCSR"
      },
      "source": [
        "Now, let's make recommendation for user 1 and compare the two list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9uInQj0gCSR"
      },
      "source": [
        "topn, topn_predict = topn_prediction(userid=test_user)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsU4JUOwgCSU",
        "outputId": "957d03c3-f540-458f-836a-3656894545ff"
      },
      "source": [
        "topn_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>similarity_with_Iu</th>\n",
              "      <th>title</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1388</td>\n",
              "      <td>26.624397</td>\n",
              "      <td>Gabbeh (1996)</td>\n",
              "      <td>4.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>359</td>\n",
              "      <td>22.973658</td>\n",
              "      <td>Assignment, The (1997)</td>\n",
              "      <td>4.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1554</td>\n",
              "      <td>27.364494</td>\n",
              "      <td>Safe Passage (1994)</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1538</td>\n",
              "      <td>24.492453</td>\n",
              "      <td>All Over Me (1997)</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1448</td>\n",
              "      <td>20.846909</td>\n",
              "      <td>My Favorite Season (1993)</td>\n",
              "      <td>4.490052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1375</td>\n",
              "      <td>20.627152</td>\n",
              "      <td>Cement Garden, The (1993)</td>\n",
              "      <td>4.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1466</td>\n",
              "      <td>21.063269</td>\n",
              "      <td>Margaret's Museum (1995)</td>\n",
              "      <td>4.271915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1516</td>\n",
              "      <td>31.133267</td>\n",
              "      <td>Wedding Gift, The (1994)</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1467</td>\n",
              "      <td>21.861203</td>\n",
              "      <td>Saint of Fort Washington, The (1993)</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1537</td>\n",
              "      <td>22.061914</td>\n",
              "      <td>Cosi (1996)</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1378</td>\n",
              "      <td>25.787842</td>\n",
              "      <td>Rhyme &amp; Reason (1997)</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1369</td>\n",
              "      <td>22.710078</td>\n",
              "      <td>Forbidden Christ, The (Cristo proibito, Il) (1...</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1550</td>\n",
              "      <td>31.031738</td>\n",
              "      <td>Destiny Turns on the Radio (1995)</td>\n",
              "      <td>3.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1189</td>\n",
              "      <td>50.362199</td>\n",
              "      <td>Prefontaine (1997)</td>\n",
              "      <td>3.666528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1506</td>\n",
              "      <td>22.325504</td>\n",
              "      <td>Nelly &amp; Monsieur Arnaud (1995)</td>\n",
              "      <td>3.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1485</td>\n",
              "      <td>24.345312</td>\n",
              "      <td>Colonel Chabert, Le (1994)</td>\n",
              "      <td>3.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1664</td>\n",
              "      <td>25.327445</td>\n",
              "      <td>8 Heads in a Duffel Bag (1997)</td>\n",
              "      <td>3.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>691</td>\n",
              "      <td>26.461802</td>\n",
              "      <td>Dark City (1998)</td>\n",
              "      <td>3.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1223</td>\n",
              "      <td>26.631850</td>\n",
              "      <td>King of the Hill (1993)</td>\n",
              "      <td>3.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1600</td>\n",
              "      <td>27.287712</td>\n",
              "      <td>Guantanamera (1994)</td>\n",
              "      <td>3.610294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>909</td>\n",
              "      <td>23.357301</td>\n",
              "      <td>Dangerous Beauty (1998)</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1261</td>\n",
              "      <td>24.785660</td>\n",
              "      <td>Run of the Country, The (1995)</td>\n",
              "      <td>3.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1255</td>\n",
              "      <td>21.750924</td>\n",
              "      <td>Broken English (1996)</td>\n",
              "      <td>3.265749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1123</td>\n",
              "      <td>24.524028</td>\n",
              "      <td>Last Time I Saw Paris, The (1954)</td>\n",
              "      <td>3.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1450</td>\n",
              "      <td>24.262120</td>\n",
              "      <td>Golden Earrings (1947)</td>\n",
              "      <td>3.142978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1474</td>\n",
              "      <td>21.877034</td>\n",
              "      <td>Nina Takes a Lover (1994)</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>766</td>\n",
              "      <td>26.590175</td>\n",
              "      <td>Man of the Year (1995)</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1356</td>\n",
              "      <td>52.867173</td>\n",
              "      <td>Ed's Next Move (1996)</td>\n",
              "      <td>2.280926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>927</td>\n",
              "      <td>20.730153</td>\n",
              "      <td>Flower of My Secret, The (Flor de mi secreto, ...</td>\n",
              "      <td>1.665010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1499</td>\n",
              "      <td>21.529748</td>\n",
              "      <td>Grosse Fatigue (1994)</td>\n",
              "      <td>1.122032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    itemid  similarity_with_Iu  \\\n",
              "7     1388           26.624397   \n",
              "18     359           22.973658   \n",
              "4     1554           27.364494   \n",
              "14    1538           24.492453   \n",
              "27    1448           20.846909   \n",
              "29    1375           20.627152   \n",
              "26    1466           21.063269   \n",
              "2     1516           31.133267   \n",
              "23    1467           21.861203   \n",
              "21    1537           22.061914   \n",
              "10    1378           25.787842   \n",
              "19    1369           22.710078   \n",
              "3     1550           31.031738   \n",
              "1     1189           50.362199   \n",
              "20    1506           22.325504   \n",
              "15    1485           24.345312   \n",
              "11    1664           25.327445   \n",
              "9      691           26.461802   \n",
              "6     1223           26.631850   \n",
              "5     1600           27.287712   \n",
              "17     909           23.357301   \n",
              "12    1261           24.785660   \n",
              "24    1255           21.750924   \n",
              "13    1123           24.524028   \n",
              "16    1450           24.262120   \n",
              "22    1474           21.877034   \n",
              "8      766           26.590175   \n",
              "0     1356           52.867173   \n",
              "28     927           20.730153   \n",
              "25    1499           21.529748   \n",
              "\n",
              "                                                title  prediction  \n",
              "7                                       Gabbeh (1996)    4.666667  \n",
              "18                             Assignment, The (1997)    4.600000  \n",
              "4                                 Safe Passage (1994)    4.500000  \n",
              "14                                 All Over Me (1997)    4.500000  \n",
              "27                          My Favorite Season (1993)    4.490052  \n",
              "29                          Cement Garden, The (1993)    4.333333  \n",
              "26                           Margaret's Museum (1995)    4.271915  \n",
              "2                            Wedding Gift, The (1994)    4.000000  \n",
              "23               Saint of Fort Washington, The (1993)    4.000000  \n",
              "21                                        Cosi (1996)    4.000000  \n",
              "10                              Rhyme & Reason (1997)    4.000000  \n",
              "19  Forbidden Christ, The (Cristo proibito, Il) (1...    4.000000  \n",
              "3                   Destiny Turns on the Radio (1995)    3.777778  \n",
              "1                                  Prefontaine (1997)    3.666528  \n",
              "20                     Nelly & Monsieur Arnaud (1995)    3.610294  \n",
              "15                         Colonel Chabert, Le (1994)    3.610294  \n",
              "11                     8 Heads in a Duffel Bag (1997)    3.610294  \n",
              "9                                    Dark City (1998)    3.610294  \n",
              "6                             King of the Hill (1993)    3.610294  \n",
              "5                                 Guantanamera (1994)    3.610294  \n",
              "17                            Dangerous Beauty (1998)    3.500000  \n",
              "12                     Run of the Country, The (1995)    3.333333  \n",
              "24                              Broken English (1996)    3.265749  \n",
              "13                  Last Time I Saw Paris, The (1954)    3.200000  \n",
              "16                             Golden Earrings (1947)    3.142978  \n",
              "22                          Nina Takes a Lover (1994)    3.000000  \n",
              "8                              Man of the Year (1995)    3.000000  \n",
              "0                               Ed's Next Move (1996)    2.280926  \n",
              "28  Flower of My Secret, The (Flor de mi secreto, ...    1.665010  \n",
              "25                              Grosse Fatigue (1994)    1.122032  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5EEllYzgCSX"
      },
      "source": [
        "As you will have noticed, the two lists are sorted in different ways. The second list is organized according to the predictions made for the user.\n",
        "\n",
        "<b>Note</b>: When making predictions for user $u$ on item $i$, user $u$ may not have rated any of the $k$ most similar items to i. In this case, we consider the mean rating of $u$ as the predicted value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ9FQoD_gCSY"
      },
      "source": [
        "## Evaluation with Mean Absolute Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlFncHmBgCSZ"
      },
      "source": [
        "from recsys.preprocessing import train_test_split, get_examples\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "def evaluate(x_test, y_test):\n",
        "    print('Evaluate the model on {} test data ...'.format(x_test.shape[0]))\n",
        "    preds = list(predict(u,i) for (u,i) in x_test)\n",
        "    mae = np.sum(np.absolute(y_test - np.array(preds))) / x_test.shape[0]\n",
        "    print('\\nMAE :', mae)\n",
        "    return mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e6Uah0OgCSa",
        "outputId": "dcf593f3-5c67-4796-914e-ebf88aa29b31"
      },
      "source": [
        "evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.672389703640273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.672389703640273"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo8awY_KgCSb"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EkbFyUcgCSb"
      },
      "source": [
        "As with the User-based CF, we have also summarised the Item-based CF into the python class [ItemToItem](https://github.com/nzhinusoftcm/review-on-collaborative-filtering/blob/master/recsys/memories/ItemToItem.py). \n",
        "\n",
        "#### ItemToItem : usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K73JoFtQgCSc"
      },
      "source": [
        "from recsys.memories.ItemToItem import ItemToItem\n",
        "from recsys.preprocessing import ids_encoder, train_test_split, get_examples\n",
        "from recsys.datasets import ml100k\n",
        "\n",
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5am0MnLhgCSd"
      },
      "source": [
        "#### Instanciate the ItemToItem CF\n",
        "\n",
        "Parameters :\n",
        "- ```k``` : number of neighbors to consider for each item\n",
        "- ```metric``` : metric to use when computing similarities : let's use **cosine**\n",
        "- ```dataset_name``` : in this example, we use the ml100k dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No4ablY5gCSe",
        "outputId": "86e9a079-8876-4c96-b3c9-e875e4d0327f"
      },
      "source": [
        "# create the Item-based CF\n",
        "item2item = ItemToItem(ratings, movies, k=20, metric='cosine', dataset_name='ml100k')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalize ratings ...\n",
            "Create the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "Item to item recommendation model created with success ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCJLUt0JgCSg",
        "outputId": "1c407c47-a08c-4dbb-bc4e-882aca17f82a"
      },
      "source": [
        "# evaluate the algorithm on test dataset\n",
        "item2item.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.507794195659005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.507794195659005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZefVmFhgCSh"
      },
      "source": [
        "#### Evaluate the Item-based CF on the ML-1M dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENke7QjOgCSi",
        "outputId": "a2104640-8470-4116-bc42-4942d0f2f34a"
      },
      "source": [
        "from recsys.memories.ItemToItem import ItemToItem\n",
        "from recsys.preprocessing import ids_encoder, train_test_split, get_examples\n",
        "from recsys.datasets import ml1m\n",
        "\n",
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# create the Item-based CF\n",
        "item2item = ItemToItem(ratings, movies, k=20, metric='cosine', dataset_name='ml1m')\n",
        "\n",
        "# evaluate the algorithm on test dataset\n",
        "print(\"=========================\")\n",
        "item2item.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalize ratings ...\n",
            "Create the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "Item to item recommendation model created with success ...\n",
            "=========================\n",
            "Evaluate the model on 100021 test data ...\n",
            "\n",
            "MAE : 0.42514728655396045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42514728655396045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS17ccy3gCSw"
      },
      "source": [
        "## Model based CF\n",
        "\n",
        "**User-based** and **Item-based CF** are memory based algorithms. They directly act on the user-item interactions to compute recommendation. To the contrary, model-based algorithms are mathematical models trained on the user-item interactions and used to predict recommendation.\n",
        "\n",
        "We will start with the SVD (Singular Value Decomposition) algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQKxYKt2gCSx"
      },
      "source": [
        "## References\n",
        "\n",
        "1. George Karypis (2001)<a href=\"https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.554.1671&rep=rep1&type=pdf\">Evaluation of Item-Based Top-N Recommendation Algorithms</a>\n",
        "2. Sarwar et al. (2001) <a href=\"https://dl.acm.org/doi/10.1145/371920.372071\"> Item-based collaborative filtering recommendation algorithms</a> \n",
        "3. Michael D. Ekstrand, et al. (2011). <a href=\"https://dl.acm.org/doi/10.1561/1100000009\"> Collaborative Filtering Recommender Systems</a>\n",
        "4. J. Bobadilla et al. (2013)<a href=\"https://romisatriawahono.net/lecture/rm/survey/information%20retrieval/Bobadilla%20-%20Recommender%20Systems%20-%202013.pdf\"> Recommender systems survey</a>\n",
        "5. Greg Linden, Brent Smith, and Jeremy York (2003) <a href=\"https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf\">Amazon.com Recommendations : Item-to-Item Collaborative Filtering</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfaCTMPtgCSy"
      },
      "source": [
        "## Author\n",
        "\n",
        "[Carmel WENGA](https://www.linkedin.com/in/carmel-wenga-871876178/), <br>\n",
        "PhD student at Universit de la Polynsie Franaise, <br> \n",
        "Applied Machine Learning Research Engineer, <br>\n",
        "[ShoppingList](https://shoppinglist.cm), NzhinuSoft."
      ]
    }
  ]
}