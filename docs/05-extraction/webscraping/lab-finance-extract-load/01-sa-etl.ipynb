{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Extract Transform Load (ETL) Lab**\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n","\n","After completing this lab you will be able to:\n","\n","*   Read CSV and JSON file types.\n","*   Extract data from the above file types.\n","*   Transform data.\n","*   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"]},{"cell_type":"markdown","metadata":{},"source":["Import the required modules and functions\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import glob                         # this module helps in selecting files \n","import pandas as pd                 # this module helps in processing CSV files\n","import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{},"source":["## Unzip Files\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip source.zip"]},{"cell_type":"markdown","metadata":{},"source":["## Set Paths\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tmpfile    = \"temp.tmp\"               # file used to store all extracted data\n","logfile    = \"logfile.txt\"            # all event logs will be stored in this file\n","targetfile = \"transformed_data.csv\"   # file where transformed data is stored"]},{"cell_type":"markdown","metadata":{},"source":["## Extract\n"]},{"cell_type":"markdown","metadata":{},"source":["### CSV Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_from_csv(file_to_process):\n","    dataframe = pd.read_csv(file_to_process)\n","    return dataframe"]},{"cell_type":"markdown","metadata":{},"source":["### JSON Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_from_json(file_to_process):\n","    dataframe = pd.read_json(file_to_process,lines=True)\n","    return dataframe"]},{"cell_type":"markdown","metadata":{},"source":["### XML Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_from_xml(file_to_process):\n","    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n","    tree = ET.parse(file_to_process)\n","    root = tree.getroot()\n","    for person in root:\n","        name = person.find(\"name\").text\n","        height = float(person.find(\"height\").text)\n","        weight = float(person.find(\"weight\").text)\n","        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n","    return dataframe"]},{"cell_type":"markdown","metadata":{},"source":["### Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract():\n","    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n","    \n","    #process all csv files\n","    for csvfile in glob.glob(\"*.csv\"):\n","        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n","        \n","    #process all json files\n","    for jsonfile in glob.glob(\"*.json\"):\n","        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n","    \n","    #process all xml files\n","    for xmlfile in glob.glob(\"*.xml\"):\n","        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n","        \n","    return extracted_data"]},{"cell_type":"markdown","metadata":{},"source":["## Transform\n"]},{"cell_type":"markdown","metadata":{},"source":["The transform function does the following tasks.\n","\n","1.  Convert height which is in inches to millimeter\n","2.  Convert weight which is in pounds to kilograms\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def transform(data):\n","        #Convert height which is in inches to millimeter\n","        #Convert the datatype of the column into float\n","        #data.height = data.height.astype(float)\n","        #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n","        data['height'] = round(data.height * 0.0254,2)\n","        \n","        #Convert weight which is in pounds to kilograms\n","        #Convert the datatype of the column into float\n","        #data.weight = data.weight.astype(float)\n","        #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n","        data['weight'] = round(data.weight * 0.45359237,2)\n","        return data"]},{"cell_type":"markdown","metadata":{},"source":["## Loading\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load(targetfile,data_to_load):\n","    data_to_load.to_csv(targetfile)  "]},{"cell_type":"markdown","metadata":{},"source":["## Logging\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def log(message):\n","    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n","    now = datetime.now() # get current timestamp\n","    timestamp = now.strftime(timestamp_format)\n","    with open(\"logfile.txt\",\"a\") as f:\n","        f.write(timestamp + ',' + message + '\\n')"]},{"cell_type":"markdown","metadata":{},"source":["## Running ETL Process\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log(\"ETL Job Started\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log(\"Extract phase Started\")\n","extracted_data = extract()\n","log(\"Extract phase Ended\")\n","extracted_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log(\"Transform phase Started\")\n","transformed_data = transform(extracted_data)\n","log(\"Transform phase Ended\")\n","transformed_data "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log(\"Load phase Started\")\n","load(targetfile,transformed_data)\n","log(\"Load phase Ended\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log(\"ETL Job Ended\")"]},{"cell_type":"markdown","metadata":{},"source":["# Exercise\n"]},{"cell_type":"markdown","metadata":{},"source":["Using the example above complete the exercise below.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Unzip Files\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  datasource.zip\n","  inflating: dealership_data/used_car_prices1.csv  \n","  inflating: dealership_data/used_car_prices2.csv  \n","  inflating: dealership_data/used_car_prices3.csv  \n","  inflating: dealership_data/used_car_prices1.json  \n","  inflating: dealership_data/used_car_prices2.json  \n","  inflating: dealership_data/used_car_prices3.json  \n","  inflating: dealership_data/used_car_prices1.xml  \n","  inflating: dealership_data/used_car_prices2.xml  \n","  inflating: dealership_data/used_car_prices3.xml  \n"]}],"source":["!unzip datasource.zip -d dealership_data"]},{"cell_type":"markdown","metadata":{},"source":["## About the Data\n"]},{"cell_type":"markdown","metadata":{},"source":["The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Set Paths\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n","logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n","targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"]},{"cell_type":"markdown","metadata":{},"source":["## Extract\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 1: CSV Extract Function\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Add the CSV extract function below\n"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","    \n","def extract_from_csv(file_to_process):\n","    dataframe = pd.read_csv(file_to_process)\n","    return dataframe\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 2: JSON Extract Function\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Add the JSON extract function below\n"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","    \n","def extract_from_json(file_to_process):\n","    dataframe = pd.read_json(file_to_process,lines=True)\n","    return dataframe\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 3: XML Extract Function\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\n"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","    \n","def extract_from_xml(file_to_process):\n","    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n","    tree = ET.parse(file_to_process)\n","    root = tree.getroot()\n","    for person in root:\n","        car_model = person.find(\"car_model\").text\n","        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n","        price = float(person.find(\"price\").text)\n","        fuel = person.find(\"fuel\").text\n","        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n","    return dataframe\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 4: Extract Function\n","\n","Call the specific extract functions you created above by replacing the `ADD_FUNCTION_CALL` with the proper function call.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def extract():\n","    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n","    \n","    #process all csv files\n","    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n","        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n","        \n","    #process all json files\n","    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n","        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n","    \n","    #process all xml files\n","    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n","        extracted_data = extracted_data.append('ADD_FUNCTION_CALL', ignore_index=True)\n","        \n","    return extracted_data"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","    \n","def extract():\n","    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n","    \n","    #process all csv files\n","    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n","        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n","        \n","    #process all json files\n","    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n","        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n","    \n","    #process all xml files\n","    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n","        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n","        \n","    return extracted_data\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Transform\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 5: Transform\n","\n","Round the `price` columns to 2 decimal places\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Add the transform function below\n"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","\n","def transform(data):\n","        data['price'] = round(data.price, 2)\n","        return data\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loading\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 6: Load\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Add the load function below\n"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","\n","def load(targetfile,data_to_load):\n","    data_to_load.to_csv(targetfile)  \n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Logging\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 7: Log\n","\n","Make sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Add the log function below\n"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","\n","def log(message):\n","    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n","    now = datetime.now() # get current timestamp\n","    timestamp = now.strftime(timestamp_format)\n","    with open(\"dealership_logfile.txt\",\"a\") as f:\n","        f.write(timestamp + ',' + message + '\\n') \n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Running ETL Process\n"]},{"cell_type":"markdown","metadata":{},"source":["### Question 8: ETL Process\n","\n","Run all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Log that you have started the ETL process\n","\n","\n","# Log that you have started the Extract step\n","\n","# Call the Extract function\n","\n","# Log that you have completed the Extract step\n","\n","\n","# Log that you have started the Transform step\n","\n","# Call the Transform function\n","\n","# Log that you have completed the Transform step\n","\n","\n","# Log that you have started the Load step\n","\n","# Call the Load function\n","\n","# Log that you have completed the Load step\n","\n","\n","# Log that you have completed the ETL process"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```\n","\n","log(\"ETL Job Started\")\n","\n","log(\"Extract phase Started\")\n","extracted_data = extract()\n","log(\"Extract phase Ended\")\n","\n","log(\"Transform phase Started\")\n","transformed_data = transform(extracted_data)\n","log(\"Transform phase Ended\")\n","\n","log(\"Load phase Started\")\n","load(targetfile,transformed_data)\n","log(\"Load phase Ended\")\n","\n","log(\"ETL Job Ended\")\n","```\n","\n","</details>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":4}
