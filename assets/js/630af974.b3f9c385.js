"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[26981],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>u});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=c(n),u=r,h=d["".concat(s,".").concat(u)]||d[u]||m[u]||i;return n?a.createElement(h,o(o({ref:t},p),{},{components:n})):a.createElement(h,o({ref:t},p))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var c=2;c<i;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},2794:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=n(87462),r=(n(67294),n(3905));const i={title:"Semantic Similarity",authors:"sparsh",tags:["nlp","similarity"]},o=void 0,l={permalink:"/blog/2021/10/01/semantic-similarity",source:"@site/blog/2021-10-01-semantic-similarity.mdx",title:"Semantic Similarity",description:"/img/content-blog-raw-blog-semantic-similarity-untitled.png",date:"2021-10-01T00:00:00.000Z",formattedDate:"October 1, 2021",tags:[{label:"nlp",permalink:"/blog/tags/nlp"},{label:"similarity",permalink:"/blog/tags/similarity"}],readingTime:1.67,hasTruncateMarker:!1,authors:[{name:"Sparsh Agarwal",title:"Data Scientist & Engineer",url:"https://github.com/sparsh-ai",email:"sprsag@gmail.com",imageURL:"https://github.com/sparsh-ai.png",key:"sparsh"}],frontMatter:{title:"Semantic Similarity",authors:"sparsh",tags:["nlp","similarity"]},prevItem:{title:"Real-time news personalization with Flink",permalink:"/blog/2021/10/01/real-time-news-personalization-with-flink"},nextItem:{title:"Short-video Background Music Recommender",permalink:"/blog/2021/10/01/short-video-background-music-recommender"}},s={authorsImageUrls:[void 0]},c=[{value:"Process Flow for Use Case 1",id:"process-flow-for-use-case-1",level:3},{value:"Process Flow for Use Case 2",id:"process-flow-for-use-case-2",level:3}],p={toc:c};function m(e){let{components:t,...i}=e;return(0,r.kt)("wrapper",(0,a.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"/img/content-blog-raw-blog-semantic-similarity-untitled.png",src:n(9551).Z,width:"715",height:"376"})),(0,r.kt)("h1",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,"Deliverable - Two paragraph-level distance outputs for L and Q, each has 35 columns. "),(0,r.kt)("p",null,"For each paragraph, we need to calculate the L1 distance of consecutive sentences in this paragraph, and then generate the mean and standard deviation of all these distances for this paragraph. For example, say the paragraph 1 starts from sentence1 and ends with sentence 5. First, calculate the L1 distances for L1(1,2), L1(2,3), L1(3,4) and L1(4,5) and then calculate the mean and standard deviation of the 4 distances. In the end we got two measures for this paragraph: L1_m and L1_std. Similarly, we need to calculate the mean and standard deviation using L2 distance, plus a simple mean and deviation of the distances. We use 6 different embeddings: all dimensions of BERT embeddings, 100,200 and 300 dimensions of PCA Bert embeddings (PCA is a dimension reduction technique "),(0,r.kt)("p",null,"In the end, we will have 35 columns for each paragraph : Paragraph ID +#sentences in the paragraph +(cosine_m, cosine_std,cossimillarity_m, cosimmilarity_std, L1_m, L1_std, L2_m, L2_std ) \u2013 by- ( all, 100, 200, 300)= 3+8*4. "),(0,r.kt)("p",null,"Note: for paragraph that only has 1 sentence, the std measures are empty."),(0,r.kt)("h1",{id:"modeling-approach"},"Modeling Approach"),(0,r.kt)("h3",{id:"process-flow-for-use-case-1"},"Process Flow for Use Case 1"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Splitting paragraphs into sentences using 1) NLTK Sentence Tokenizer, 2) Spacy Sentence Tokenizer and, on two additional symbols ",(0,r.kt)("inlineCode",{parentName:"li"},":")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"...")),(0,r.kt)("li",{parentName:"ol"},"Text Preprocessing: Lowercasing, Removing Non-alphanumeric characters, Removing Null records, Removing sentence records (rows) having less than 3 words."),(0,r.kt)("li",{parentName:"ol"},"TF-IDF vectorization"),(0,r.kt)("li",{parentName:"ol"},"LSA over document-term matrix"),(0,r.kt)("li",{parentName:"ol"},"Cosine distance calculation of adjacent sentences (rows)")),(0,r.kt)("h3",{id:"process-flow-for-use-case-2"},"Process Flow for Use Case 2"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Split paragraphs into sentences"),(0,r.kt)("li",{parentName:"ul"},"Text cleaning"),(0,r.kt)("li",{parentName:"ul"},"BERT Sentence Encoding"),(0,r.kt)("li",{parentName:"ul"},"BERT PCA 100"),(0,r.kt)("li",{parentName:"ul"},"BERT PCA 200"),(0,r.kt)("li",{parentName:"ul"},"BERT PCA 300"),(0,r.kt)("li",{parentName:"ul"},"Calculate distance between consecutive sentences in the paragraph"),(0,r.kt)("li",{parentName:"ul"},"Distances: L1, L2 and Cosine and Cosine similarity"),(0,r.kt)("li",{parentName:"ul"},"Statistics: Mean, SD")),(0,r.kt)("h1",{id:"experimental-setup"},"Experimental Setup"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"#IncrementalPCA"),(0,r.kt)("li",{parentName:"ol"},"GPU to speed up"),(0,r.kt)("li",{parentName:"ol"},"Data chunking"),(0,r.kt)("li",{parentName:"ol"},"Calculate BERT for a chunk and store in disk")))}m.isMDXComponent=!0},9551:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/content-blog-raw-blog-semantic-similarity-untitled-7d572e51518b870475eaa94a0500aed6.png"}}]);