"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[77821],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>p});var s=a(67294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);t&&(s=s.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,s)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,s,n=function(e,t){if(null==e)return{};var a,s,n={},o=Object.keys(e);for(s=0;s<o.length;s++)a=o[s],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(s=0;s<o.length;s++)a=o[s],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var d=s.createContext({}),l=function(e){var t=s.useContext(d),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=l(e.components);return s.createElement(d.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return s.createElement(s.Fragment,{},t)}},h=s.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,d=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),h=l(a),p=n,m=h["".concat(d,".").concat(p)]||h[p]||u[p]||o;return a?s.createElement(m,r(r({ref:t},c),{},{components:a})):s.createElement(m,r({ref:t},c))}));function p(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,r=new Array(o);r[0]=h;var i={};for(var d in t)hasOwnProperty.call(t,d)&&(i[d]=t[d]);i.originalType=e,i.mdxType="string"==typeof e?e:n,r[1]=i;for(var l=2;l<o;l++)r[l]=a[l];return s.createElement.apply(null,r)}return s.createElement.apply(null,a)}h.displayName="MDXCreateElement"},87696:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>l});var s=a(87462),n=(a(67294),a(3905));const o={title:"The progression of analytics in enterprises",authors:"sparsh",tags:["insight"]},r=void 0,i={permalink:"/blog/2021/10/01/the-progression-of-analytics-in-enterprises",source:"@site/blog/2021-10-01-the-progression-of-analytics-in-enterprises.mdx",title:"The progression of analytics in enterprises",description:"An organization\u2019s analytics strategy is how its\xa0people, processes, tools, and data\xa0work together to collect, store, and analyze data. Processes\xa0refers to\xa0how\xa0analytics are produced, consumed, and maintained. A more modern approach to analytics is intended to support greater business agility at scale. This requires faster data preparation from a wider variety of sources, rapid prototyping and analytics model building, and cross-team collaboration processes. Tools, or technologies, are the raw programs and applications used to prepare for and perform analyses, such as the provisioning, flow, and automation of tasks and resources. As an analytics strategy matures, the technologies used to implement it tend to move from monolithic structures to composable microservices. The last element is\xa0data. A modern analytics architecture supports a growing volume and variety of data sources, which may include data from data warehouses and data lakes\u2014streaming data, relational databases, graph databases, unstructured or semi-structured data, text data, and images.",date:"2021-10-01T00:00:00.000Z",formattedDate:"October 1, 2021",tags:[{label:"insight",permalink:"/blog/tags/insight"}],readingTime:12.09,hasTruncateMarker:!1,authors:[{name:"Sparsh Agarwal",title:"Data Scientist & Engineer",url:"https://github.com/sparsh-ai",email:"sprsag@gmail.com",imageURL:"https://github.com/sparsh-ai.png",key:"sparsh"}],frontMatter:{title:"The progression of analytics in enterprises",authors:"sparsh",tags:["insight"]},prevItem:{title:"Short-video Background Music Recommender",permalink:"/blog/2021/10/01/short-video-background-music-recommender"},nextItem:{title:"Tools for building recommender systems",permalink:"/blog/2021/10/01/tools-for-building-recommender-systems"}},d={authorsImageUrls:[void 0]},l=[{value:"Analytics Past, Present, and Future",id:"analytics-past-present-and-future",level:3}],c={toc:l};function u(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,s.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"An organization\u2019s analytics strategy is how its\xa0",(0,n.kt)("em",{parentName:"p"},"people, processes, tools, and data"),"\xa0work together to collect, store, and analyze data. ",(0,n.kt)("em",{parentName:"p"},"Processes"),"\xa0refers to\xa0",(0,n.kt)("em",{parentName:"p"},"how"),"\xa0analytics are produced, consumed, and maintained. A more modern approach to analytics is intended to support greater business agility at scale. This requires faster data preparation from a wider variety of sources, rapid prototyping and analytics model building, and cross-team collaboration processes. ",(0,n.kt)("em",{parentName:"p"},"Tools"),", or technologies, are the raw programs and applications used to prepare for and perform analyses, such as the provisioning, flow, and automation of tasks and resources. As an analytics strategy matures, the technologies used to implement it tend to move from monolithic structures to composable microservices. The last element is\xa0",(0,n.kt)("em",{parentName:"p"},"data.")," A modern analytics architecture supports a growing volume and variety of data sources, which may include data from data warehouses and data lakes\u2014streaming data, relational databases, graph databases, unstructured or semi-structured data, text data, and images."),(0,n.kt)("h3",{id:"analytics-past-present-and-future"},"Analytics Past, Present, and Future"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null}),(0,n.kt)("th",{parentName:"tr",align:null},"Past"),(0,n.kt)("th",{parentName:"tr",align:null},"Present"),(0,n.kt)("th",{parentName:"tr",align:null},"Future"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null}),(0,n.kt)("td",{parentName:"tr",align:null},"This refers to an era of analytics starting in the 1990s and running through the mid-2000s. During this phase, organizations were able to consolidate mostly transactional data into a unified system, often a\xa0data warehouse, which limited end users\u2019 ability to interact directly with the data due to technical and governance requirements."),(0,n.kt)("td",{parentName:"tr",align:null},"Starting in the late 2000s, organizations were forced to rethink how they used analytics, in no small part due to the explosion of data during this time. This was the era of \u201cBig Data\u201d and its infamous\xa0\u201c V\u2019s\u201d:\xa0volume, velocity, and variety.4\xa0As organizations shifted their approach during this period, they unlocked\xa0diagnostic analytics, or the capability to answer \u201cWhy did it happen?\u201d"),(0,n.kt)("td",{parentName:"tr",align:null},"The Future of Analytics Is Converged. Converged analytics unifies advances in AI, streaming data, and related technologies into a seamless analytics experience for all users. This arrangement unlocks\xa0prescriptive\xa0analytics across an organization, allowing anyone to make data-driven decisions that answer important questions.")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"People"),(0,n.kt)("td",{parentName:"tr",align:null},"IT professionals were needed to kick off any data-based work by extracting data from a centralized, difficult-to-use source. This process could take multiple days, and the number of query requests could easy exceed the IT team\u2019s ability to fulfill those requests\u2014and the opportune time for new insights.If some change was needed to data collection or storage methods, it could easily take IT months to perform. The data analysis and modeling work could take nearly as long. Rank-and-file domain experts did have\xa0some\xa0access to data, through so-called\xa0self-service business intelligence (BI)\xa0features. However, due to the same speed and accessibility issues that technical professionals faced, it was often difficult for domain experts like line of business leaders to truly lead with data for decision making."),(0,n.kt)("td",{parentName:"tr",align:null},"It\u2019s no coincidence that around the same time as Big Data emerged, so did the role of the\xa0data scientist. Compared with earlier roles like researcher or statistician, the data scientist blends quantitative and domain expertise with a greater degree of computational thinking. These skills became necessary both to handle the greater variety and volume of data sources and to update and deploy data and analytics models without the assistance of IT professionals.Whereas IT in the past sought to meticulously catalog and structure data to enter into a data warehouse, they no longer needed to always clean the data before collecting it; these analytics teams could focus on ease of use and speed to governed access.With these new workflows and organization structures in place, domain leaders are better able to lead with data: both via self-service BI tools and from frequent collaboration with data analysts, data scientists, and other data specialists."),(0,n.kt)("td",{parentName:"tr",align:null},"Statisticians and IT served information to business users at the inception of a wider analytics adoption; further into maturity, data analysts and scientists built systems where business users could self-serve insights. In a converged architecture, not only is the business user at the center, but their decision making is augmented by automation. Given this arrangement, there is more collaboration, more automation, and greater scale for data-driven insights as a result of the convergence of teams and workstreams. Teams can work cross-functionally and in parallel across different domains iterating the system to their needs with the raw time and human resources needed to create and maintain analytics products such as dashboards and models.")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Processes"),(0,n.kt)("td",{parentName:"tr",align:null},"IT professionals spent long periods of time gathering requirements for analytics projects before they could build or deploy solutions. The team meticulously catalogued sources of data used across the organization, from financial or point-of-sale systems to frequently used external datasets. As part of the warehousing process, it was decided\xa0which\xa0of these data sources to store and\xa0how\xa0to store them.Once deployed, data passed into the warehouse through an\xa0extract-transform-load\xa0process (ETL), where the data was copied from these various sources, cleaned and reshaped into the defined structure of the data warehouse, then inserted into production. In other words, data went through rigorous cleaning and preprocessing\xa0before\xa0use.To reach this data, users needed to write time-consuming ad hoc queries. Alternatively, particular data segments or summaries that were frequently requested by business users could be delivered via scheduled automation to reports, dashboards, and scorecards."),(0,n.kt)("td",{parentName:"tr",align:null},"As opposed to earlier analytics strategies, IT professionals now seek to collect data as is from any possible source of value. This data can be in a variety of formats, so few predefined rules or relationships are established for ingestion. Depending on the data size, data is processed in batch over discrete time periods, or in streams and events near real time. Because data cleaning is the last step, this process is sometimes referred to as\xa0extract-load-transform\xa0(ELT), as opposed to the ETL of earlier architectures. For data scientists and other technical professionals, faster access to more\xa0and more dynamic\xa0data better enables the rapid development of training sets of data for machine learning models. The ELT process allows for the construction of\xa0machine learning\xa0models, where computers are able to improve performance as more data is passed to them.As more data is collected and put into production, the importance of a\xa0data governance\xa0process typically grows, describing who has authority over data and how that data should be used. Similar approaches are necessary to audit how models are put into production and how they work."),(0,n.kt)("td",{parentName:"tr",align:null},"While perhaps using different\xa0means, the\xa0ends\xa0of older analytics approaches were the same: insights, whether historic or in support of future decisions, using governed data and processes. In the methods for doing so, however, infrastructure tended to bloat, either from fragile data storage jobs or increasingly complex data pipelines.Given the volume, velocity, and variety of data needed for prescriptive analytics, such monolithic, centralized approaches are less than optimal. Using the tools discussed in the next section, a converged architecture offers a more nimble approach for providing the right insights at the right time to users of all technical levels.Such democratization relies on quick deployment and adjustment of data products; optimizing production, for example, requires bringing more machine learning models to production faster and at scale. The practice of\xa0ModelOps\xa0is used to institute and govern such rapid production. These processes have become a necessity in rapidly changing business conditions; for example, as the COVID-19 pandemic made structural changes to the economy, many models lost their predictive edge in the face of fundamentally different data.")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Tools"),(0,n.kt)("td",{parentName:"tr",align:null},"Data warehouses implemented some new technologies relative to the traditional relational database model. Importantly, the data warehouse separated data into\xa0fact\xa0tables, where measurements were stored, and\xa0dimension\xa0tables, which contained descriptive attributes. Business users interacted with the data via reporting software to view static data summaries. These tended to rely on overnight batch jobs to update.In a more sophisticated architecture, analysts could take advantage of\xa0online analytical processing\xa0(OLAP) cubes. Usually relying on a star schema, OLAP let users query the data across dimensions during interactive sessions. For example, they could \u201cslice and dice\u201d or \u201croll up and drill down\u201d on the data.By this point, end users had some autonomy in how they looked at and acted upon the data. Automated processes to inform business activities through data were also put into place, such as alerts when inventory or sales dropped below some threshold. Basic what-if analyses also helped business users evaluate decisions and plan for the future.That said, given the limited sources of data from the data warehouse, there were limited ways to customize and work with the data. While reporting and basic analytics were automated, end users operated largely without the assistance of models developed by\xa0statisticians. Although business intelligence and operations research seek to create value from data, too often these complementary tools were siloed."),(0,n.kt)("td",{parentName:"tr",align:null},"In 2011, James Dixon, then chief technology officer of Pentaho, coined the term\xa0data lake\xa0as the architecture needed to support the next level of analytics maturity.\xa0Dixon argued that because of the inherently rigid structures of data warehouses, getting value from the increasing volume and variety of data associated with Big Data was difficult. A data lake, \u201ca repository of data stored in its natural/raw format,\u201d was a better approach. In particular, this arrangement wasn\u2019t suited to operate or capitalize on the expanding volume and variety of Big Data.The data lake is often powered by cloud computing for the benefits of reliability, redundancy, and scalability. Dominant cloud service providers include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP). Open source technologies like Hadoop and Spark are used to process and store massive datasets using parallel computing and distributed storage. Because this data is often unstructured, it may be stored in graph, document, or other non-relational databases.With the increasing volume and velocity of data, and the use of data lakes along with data warehouses to enable data-driven decisions, businesses needed better ways to scale and share business intelligence. One such path was through interactive, immersive exploration and visualization of the data, as pioneered with Spotfire. Other paths were through visual reports and dashboards, as used by not just Spotfire, but by Jaspersoft, Power BI, WebFOCUS, and many others. As BI tools matured, self-service capabilities and automation for end users also matured."),(0,n.kt)("td",{parentName:"tr",align:null},"If maintaining legacy analytics is like raising a thoroughbred, then developing converged analytics is like cultivating a school of goldfish. That is, the backend provisioning is no longer served by monolithic systems but rather by composable groups of\xa0microservices. This arrangement supports elastic and scalable analytics; composability makes it easier to adapt to changes driven in part by a growing volume and variety of data sources. In previous analytics approaches, the distinction between backward-facing BI and prediction-focused data science was clear. Under convergence, analytics at the edge is possible\u2014automating analytic computations so they can be performed on non-centralized data generated by sensors, switches, and similar. With converged analytics, individuals no longer need to wait for data science teams to provide ad hoc deeper insights. They have all the data-driven insights at their fingertips, assisted by AI to quickly explore and make decisions. This isn\u2019t just the case for back-office analysts: frontline workers can, for example, adjust how they interact with a customer given data retrieved about that customer at the time of that interaction.")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Data"),(0,n.kt)("td",{parentName:"tr",align:null},"During this period, data tended to be\xa0transactional, or related to sales and purchases. Take a point-of-sales (POS) system, for example. Each time a sale is made, information about what was sold,\xa0possibly\xa0to whom, is recorded in the POS system. Those records can be compiled into tables and ultimately processed into a data\xa0warehouse.Under this process, data is gathered from prespecified sources at prespecified times, such as a nightly POS extract. Not all data made its way to the data warehouse, especially in the earlier days of analytics\u2014either because it was judged unimportant, or because it was not prioritized."),(0,n.kt)("td",{parentName:"tr",align:null},"Contemporary analytics expands the variety of data available and used: both\xa0structured\xa0tables and\xa0unstructured\xa0sources like natural language and images are available. On account of stream processing, refreshes of this data are available in minutes or even less. In particular, the data lake can accommodate real-time events such as IoT sensor readings, GPS signals, and online transactions as they\xa0happen."),(0,n.kt)("td",{parentName:"tr",align:null},"A primary feature of converged analytics is the blending of historical and real-time data. According to a study by Seagate and International Data Corporation (IDC), 30% of all data will be real time by 2025. In particular, IoT sensor readings, GPS signals, and online transactions as they happen are available for immediate analysis and modeling.")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Agility"),(0,n.kt)("td",{parentName:"tr",align:null},"The relatively rigid nature of the data warehouse made changes to the collection and dissemination of data difficult. Subsequently, business agility was limited. Business users could get historic data about the business through static reports (descriptive analytics). Through OLAP cubes, they could possibly even dig into the data to parse out cause and effect (diagnostic analytics). But without more immediate access to broader data, it was difficult to advance to\xa0predictive analytics, or the ability to ask: \u201cWhat is\xa0going\xa0to happen?\u201d"),(0,n.kt)("td",{parentName:"tr",align:null},"This next phase in the evolution of analytics gets data-driven insights into the hands of end users quickly, with technology allowing them to interact with it on a deeper level. Data scientists are able to build machine learning systems that improve with more data. Using drag-and-drop tools, business users can process and analyze data without technical assistance. With cloud, automation, and streaming technologies, organizations have been better able to adapt to and plan for changing circumstances. That said, machine learning works only so long in production before the algorithm struggles to account for changes to the business and needs intervention. While data scientists undertake these predictive challenges, BI professionals and domain experts tend to operate solely in analyzing current or past data. The next generation of analytics architecture will further reflect organizational needs for greater collaboration among data scientists, BI and analytics teams, and business users and consumers of analytics insights."),(0,n.kt)("td",{parentName:"tr",align:null},"Earlier analytics tended to isolate skills and processes: technical versus highly technical roles, data collection versus deployment versus modeling, and so forth. Converged analytics promotes close collaboration between teams to rapidly model, deploy, and act on data. As data operations become decentralized, teams and individuals can rapidly mine and act on the analytics.In particular, the marriage of real-time data with machine learning and AI-infused BI allows any user to magnify their own domain knowledge with data-driven insights. These features square precisely with the definition of business agility as \u201cinnovation via collaboration to be able to anticipate challenges and opportunities before they occur.\u201d With the support of converged analytics, any professional can detect and act on both challenges and opportunities at the moment of impact, rather than months later.")))),(0,n.kt)("hr",null),(0,n.kt)("p",null,"\xa9\ufe0f2021, RecoHut."))}u.isMDXComponent=!0}}]);