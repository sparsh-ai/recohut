<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Image Similarity System | Recohut Data Bootcamp</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.recohut.com/blog/2021/10/01/image-similarity-system"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" name="keywords" content="data science, data engineering, data analytics"><meta data-rh="true" property="og:title" content="Image Similarity System | Recohut Data Bootcamp"><meta data-rh="true" name="description" content="/img/content-blog-raw-blog-image-similarity-system-untitled.png"><meta data-rh="true" property="og:description" content="/img/content-blog-raw-blog-image-similarity-system-untitled.png"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2021-10-01T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/sparsh-ai"><meta data-rh="true" property="article:tag" content="aws beanstalk,flask,similarity,vision"><link data-rh="true" rel="icon" href="/img/branding/favicon-black.svg"><link data-rh="true" rel="canonical" href="https://www.recohut.com/blog/2021/10/01/image-similarity-system"><link data-rh="true" rel="alternate" href="https://www.recohut.com/blog/2021/10/01/image-similarity-system" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.recohut.com/blog/2021/10/01/image-similarity-system" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut Data Bootcamp RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Data Bootcamp Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B4S1B1ZDTT"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B4S1B1ZDTT",{})</script><link rel="stylesheet" href="/assets/css/styles.e4e34528.css">
<link rel="preload" href="/assets/js/runtime~main.166317d0.js" as="script">
<link rel="preload" href="/assets/js/main.3580ce8c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bootcamp</b></a><a class="navbar__item navbar__link" href="/docs/bootcamp">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sparsh-ai/recohut" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2022/12/24/ab-mab-tests">A/B and Multi-Armed Bandit Tests</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2022/12/13/sql-to-snowflake-schema-conversion">SQL Server to Snowflake Schema Conversion</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2022/12/12/the-complete-python-course-2022">The Complete Python Course (2022)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2022/11/16/opening-material">Opening our Bootcamp material</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2021/10/01/clinical-decision-making">Clinical Decision Making</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">Image Similarity System</h1><div class="container_mt6G margin-vert--md"><time datetime="2021-10-01T00:00:00.000Z" itemprop="datePublished">October 1, 2021</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/sparsh-ai" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/sparsh-ai.png" alt="Sparsh Agarwal"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/sparsh-ai" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Sparsh Agarwal</span></a></div><small class="avatar__subtitle" itemprop="description">Data Scientist &amp; Engineer</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="/img/content-blog-raw-blog-image-similarity-system-untitled.png" src="/assets/images/content-blog-raw-blog-image-similarity-system-untitled-59c540a72e9f8afbece0d5a9bd41f513.png" width="1289" height="545" class="img_ev3q"></p><h1>Choice of variables</h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="image-encoder">Image Encoder<a class="hash-link" href="#image-encoder" title="Direct link to heading">​</a></h3><p>We can select any pre-trained image classification model. These models are commonly known as encoders because their job is to encode an image into a feature vector. I analyzed four encoders named 1) MobileNet, 2) EfficientNet, 3) ResNet and 4) <a href="https://tfhub.dev/google/bit/m-r152x4/1" target="_blank" rel="noopener noreferrer">BiT</a>. After basic research, I decided to select BiT model because of its performance and state-of-the-art nature. I selected the BiT-M-50x3 variant of model which is of size 748 MB. More details about this architecture can be found on the official page <a href="https://tfhub.dev/google/bit/m-r50x3/1" target="_blank" rel="noopener noreferrer">here</a>. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="vector-similarity-system">Vector Similarity System<a class="hash-link" href="#vector-similarity-system" title="Direct link to heading">​</a></h3><p>Images are represented in a fixed-length feature vector format. For the given input vector, we need to find the TopK most similar vectors, keeping the memory efficiency and real-time retrival objective in mind. I explored the most popular techniques and listed down five of them: Annoy, Cosine distance, L1 distance, Locally Sensitive Hashing (LSH) and Image Deep Ranking. I selected Annoy because of its fast and efficient nature. More details about Annoy can be found on the official page <a href="https://github.com/spotify/annoy" target="_blank" rel="noopener noreferrer">here</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataset">Dataset<a class="hash-link" href="#dataset" title="Direct link to heading">​</a></h3><p>I listed down 3 datasets from Kaggle that were best fitting the criteria of this use case: 1) <a href="https://www.kaggle.com/bhaskar2443053/fashion-small?" target="_blank" rel="noopener noreferrer">Fashion Product Images (Small)</a>, 2) <a href="https://www.kaggle.com/trolukovich/food11-image-dataset?" target="_blank" rel="noopener noreferrer">Food-11 image dataset</a> and 3) <a href="https://www.kaggle.com/jessicali9530/caltech256?" target="_blank" rel="noopener noreferrer">Caltech 256 Image Dataset</a>. I selected Fashion dataset and Foods dataset.</p><h1>Literature review</h1><ul><li>Determining Image similarity with Quasi-Euclidean Metric <a href="https://arxiv.org/abs/2006.14644v1" target="_blank" rel="noopener noreferrer">arxiv</a></li><li>CatSIM: A Categorical Image Similarity Metric <a href="https://arxiv.org/abs/2004.09073v1" target="_blank" rel="noopener noreferrer">arxiv</a></li><li>Central Similarity Quantization for Efficient Image and Video Retrieval <a href="https://arxiv.org/abs/1908.00347v5" target="_blank" rel="noopener noreferrer">arxiv</a></li><li>Improved Deep Hashing with Soft Pairwise Similarity for Multi-label Image Retrieval <a href="https://arxiv.org/abs/1803.02987v3" target="_blank" rel="noopener noreferrer">arxiv</a></li><li>Model-based Behavioral Cloning with Future Image Similarity Learning <a href="https://arxiv.org/abs/1910.03157v1" target="_blank" rel="noopener noreferrer">arxiv</a></li><li>Why do These Match? Explaining the Behavior of Image Similarity Models <a href="https://arxiv.org/abs/1905.10797v1" target="_blank" rel="noopener noreferrer">arxiv</a></li><li>Learning Non-Metric Visual Similarity for Image Retrieval <a href="https://arxiv.org/abs/1709.01353v2" target="_blank" rel="noopener noreferrer">arxiv</a></li></ul><h1>Process Flow</h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-data-acquisition">Step 1: Data Acquisition<a class="hash-link" href="#step-1-data-acquisition" title="Direct link to heading">​</a></h3><p>Download the raw image dataset into a directory. Categorize these images into their respective category directories. Make sure that images are of the same type, JPEG recommended. We will also process the metadata and store it in a serialized file, CSV recommended. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-encoder-fine-tuning">Step 2: Encoder Fine-tuning<a class="hash-link" href="#step-2-encoder-fine-tuning" title="Direct link to heading">​</a></h3><p>Download the pre-trained image model and add two additional layers on top of that: the first layer is a feature vector layer and the second layer is the classification layer. We will only train these 2 layers on our data and after training, we will select the feature vector layer as the output of our fine-tuned encoder. After fine-tuning the model, we will save the feature extractor for later use.</p><p><img loading="lazy" alt="Fig: a screenshot of encoder fine-tuning process" src="/assets/images/content-blog-raw-blog-image-similarity-system-untitled-1-66cd649b6c0e03c173f3e0734b2b3312.png" width="1195" height="333" class="img_ev3q"></p><p>Fig: a screenshot of encoder fine-tuning process</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-image-vectorization">Step 3: Image Vectorization<a class="hash-link" href="#step-3-image-vectorization" title="Direct link to heading">​</a></h3><p>Now, we will use the encoder (prepared in step 2) to encode the images (prepared in step 1). We will save feature vector of each image as an array in a directory. After processing, we will save these embeddings for later use.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-metadata-and-indexing">Step 4: Metadata and Indexing<a class="hash-link" href="#step-4-metadata-and-indexing" title="Direct link to heading">​</a></h3><p>We will assign a unique id to each image and create dictionaries to locate information of this image: 1) Image id to Image name dictionary, 2) Image id to image feature vector dictionary, and 3) (optional) Image id to metadata product id dictionary. We will also create an image id to image feature vector indexing. Then we will save these dictionaries and index object for later use.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-api-call">Step 5: API Call<a class="hash-link" href="#step-5-api-call" title="Direct link to heading">​</a></h3><p>We will receive an image from user, encode it with our image encoder, find TopK similar vectors using Indexing object, and retrieve the image (and metadata) using dictionaries. We send these images (and metadata) back to the user.</p><h1>Deployment</h1><p>The API was deployed on AWS cloud infrastructure using AWS Elastic Beanstalk service.</p><p><img loading="lazy" alt="/img/content-blog-raw-blog-image-similarity-system-untitled-2.png" src="/assets/images/content-blog-raw-blog-image-similarity-system-untitled-2-ca3d98690fca750590d55d9899c4d862.png" width="1883" height="593" class="img_ev3q"></p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/aws-beanstalk">aws beanstalk</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flask">flask</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/similarity">similarity</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/vision">vision</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/2021/10/01/fake-voice-detection"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Fake Voice Detection</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/2021/10/01/insurance-personalization"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Insurance Personalization</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#image-encoder" class="table-of-contents__link toc-highlight">Image Encoder</a></li><li><a href="#vector-similarity-system" class="table-of-contents__link toc-highlight">Vector Similarity System</a></li><li><a href="#dataset" class="table-of-contents__link toc-highlight">Dataset</a></li><li><a href="#step-1-data-acquisition" class="table-of-contents__link toc-highlight">Step 1: Data Acquisition</a></li><li><a href="#step-2-encoder-fine-tuning" class="table-of-contents__link toc-highlight">Step 2: Encoder Fine-tuning</a></li><li><a href="#step-3-image-vectorization" class="table-of-contents__link toc-highlight">Step 3: Image Vectorization</a></li><li><a href="#step-4-metadata-and-indexing" class="table-of-contents__link toc-highlight">Step 4: Metadata and Indexing</a></li><li><a href="#step-5-api-call" class="table-of-contents__link toc-highlight">Step 5: API Call</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Bootcamp. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.166317d0.js"></script>
<script src="/assets/js/main.3580ce8c.js"></script>
</body>
</html>