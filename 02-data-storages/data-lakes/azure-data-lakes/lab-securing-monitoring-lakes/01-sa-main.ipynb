{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Lake forms the key storage layer for data engineering pipelines. Security and the monitoring of Data Lake accounts are key aspects of Data Lake maintenance. This lab will focus on configuring security controls such as firewalls, encryption, and creating private links to a Data Lake account. By the end of this lab, you will have learned how to configure a firewall, virtual network, and private link to secure the Data Lake, encrypt Data Lake using Azure Key Vault, and monitor key user actions in Data Lake.\n",
    "\n",
    "We will be covering the following recipes in this lab:\n",
    "\n",
    "-   Configuring a firewall for an Azure Data Lake account using the Azure portal\n",
    "-   Configuring virtual networks for an Azure Data Lake account using the Azure portal\n",
    "-   Configuring private links for an Azure Data Lake account\n",
    "-   Configuring encryption using Azure Key Vault for Azure Data Lake\n",
    "-   Accessing Blob storage accounts using managed identities\n",
    "-   Creating an alert to monitor an Azure Data Lake account\n",
    "-   Securing an Azure Data Lake account with an SAS using PowerShell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 1 - Configuring a firewall for an Azure Data Lake account using the Azure portal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Lake account access can be restricted to an IP or a range of IPs by whitelisting the allowed IPs in the storage account firewall. In this recipe, we'll learn to restrict access to a Data Lake account using a firewall.\n",
    "\n",
    "To provide access to an IP or range of IPs, follow these steps:\n",
    "\n",
    "1. On the storage account page, in the Security + Networking section, locate and select Firewalls and virtual networks\n",
    "1. In the Selected networks option, scroll down to the Firewall section. To give access to your machine only, select the Add your client IP address option. To give access to a different IP or range of IPs, type in the IPs in the Address range section\n",
    "1. To access storage accounts from Azure services such as Azure Data Factory and Azure Functions, check Allow Azure services on the trusted services list to access this storage account under the Exceptions heading\n",
    "1. Click Save to save the configuration changes.\n",
    "\n",
    "How it works…\n",
    "\n",
    "Firewall settings are used to restrict access to an Azure storage account to an IP or range of IPs. Even if a storage account is public, it will only be accessible to the whitelisted IPs defined in the firewall configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 2 - Configuring virtual networks for an Azure Data Lake account using the Azure portal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A storage account can be public which is accessible to everyone, public with access to an IP or range of IPs, or private with access to selected virtual networks. In this recipe, we'll learn how to restrict access to an Azure storage account in a virtual network.\n",
    "\n",
    "To restrict access to a virtual network, follow the given steps:\n",
    "\n",
    "1. On the storage account page, in the Security + Network section, locate and select Firewalls and virtual networks | Selected networks\n",
    "1. In the Virtual networks section, select + Add new virtual network\n",
    "1. In the Create virtual network blade, provide the virtual network name, Address space details, and Subnet address range. The remainder of the configuration values are pre-filled\n",
    "1. Click on Create to create the virtual network. This is created and listed in the Virtual Network section\n",
    "1. Click Save to save the configuration changes\n",
    "\n",
    "How it works…\n",
    "\n",
    "We first created an Azure virtual network and then added it to the Azure storage account. Creating the Azure virtual network from the storage account page automatically fills in the resource group, location, and subscription information. The virtual network and the storage account should be in the same location.\n",
    "\n",
    "The address space specifies the number of IP addresses in a given virtual network.\n",
    "\n",
    "We also need to define the subnet within the virtual network that the storage account will belong to. We can also create a custom subnet. In our case, for the sake of simplicity, we have used the default subnet.\n",
    "\n",
    "This allows the storage account to only be accessed by resources that belong to the given virtual network. The storage account is inaccessible to any network other than the specified virtual network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe 3 - Configuring encryption using Azure Key Vault for Azure Data Lake"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this recipe, we will create a key vault and use it to encrypt an Azure Data Lake account.\n",
    "\n",
    "Azure Data Lake accounts are encrypted at rest by default using Azure managed keys. However, you have the option of bringing your own key to encrypt an Azure Data Lake account. Using your own key gives better control over encryption.\n",
    "\n",
    "Perform the following steps to add encryption to a Data Lake account using Azure Key Vault:\n",
    "\n",
    "1. Log in to portal.azure.com, click on Create a resource, search for Key Vault, and click on Create. Provide the key vault details, Click on Review + Create\n",
    "1. Go to the storage account to be encrypted. Search for Encryption on the left. Click on Encryption and select Customer-managed keys as the Encryption type. Click on Select a key vault and key at the bottom\n",
    "1. On the new screen, Select a key, select Key vault as Key store type and select the newly created KeyVault as Key vault. Click on Create new key\n",
    "1. Provide a name for the key to be used for encryption of the storage account. The default option, Generate, ensures that the key is generated automatically. Click on Create\n",
    "1. Once the key is created, the screen automatically moves to the key vault selection page in the Blob storage, and the newly created key is selected as the key. Click on Select\n",
    "1. The screen moves to the encryption page on the Blob storage page. Click on Save to complete the encryption configuration\n",
    "\n",
    "How it works…\n",
    "\n",
    "As the newly created key vault has been set for encryption on an Azure Data Lake account, all Data Lake operations (read, write, and metadata) will use the key from Key Vault to encrypt and decrypt the data in Data Lake. The encryption and decryption operations are fully transparent and have no impact on users' operations.\n",
    "\n",
    "The Data Lake account automatically gets permissions on the key vault to extract the key and perform encryption on data. You can verify this by opening the key vault in the Azure portal and clicking on Access Policies. Note that the storage account has been granted Get, wrap, and unwrap permissions on the keys."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipt 4 - Creating an alert to monitor an Azure storage account"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an alert on multiple available metrics to monitor an Azure storage account. To create an alert, we need to define the trigger condition and the action to be performed when the alert is triggered. In this recipe, we'll create an alert to send an email if the used capacity metrics for an Azure storage account exceed 5 MB. The used capacity threshold of 5 MB is not a standard and is deliberately kept low to explain the alert functionality.\n",
    "\n",
    "Follow these steps to create an alert:\n",
    "\n",
    "1. On the storage account page, search for alert and open Alerts in the Monitoring section\n",
    "1. On the Alerts page, click on + New alert rule:\n",
    "1. On the Alerts | Create alert rule page, observe that the storage account is listed by default in the Resource section. You can add multiple storage accounts in the same alert. Under the Condition section, click Add condition\n",
    "1. On the Configure signal logic page, select Used capacity under Signal name\n",
    "1. On the Configure signal logic page, under Alert logic, set Operator to Greater than, Aggregation type to Average, and configure the threshold to 5 MiB. We need to provide the value in bytes\n",
    "1. Click Done to configure the trigger. The condition is added, and we'll be taken back to the Create alert rule page\n",
    "1. The next step is to add an action to perform when the alert condition is reached. On the Create alert rule page, in the ACTIONS GROUPS section, click Create\n",
    "1. On the Add action group page, provide the Action group name, Display name, and Resource group details\n",
    "1. In Notifications, provide an email address. Click on Review + Create\n",
    "1. Click on Create to create the action group. We are then taken back to the Create rule page. The Email action is listed in the Action Groups section.\n",
    "1. The next step is to define the Severity, Alert rule name, and Alert rule description details\n",
    "1. Click the Create alert rule button to create the alert.\n",
    "1. The next step is to trigger the alert. To do that, download BigFile.csv from the data folder to the Azure storage account. The triggered alerts are listed on the Alerts page.\n",
    "1. An email is sent to the email ID specified in the email action group.\n",
    "\n",
    "How it works…\n",
    "\n",
    "Setting up an alert is easy. At first, we need to define the alert condition (a trigger or signal). An alert condition defines the metrics and threshold that, when breached, trigger the alert. We can define more than one condition on multiple metrics for one alert.\n",
    "\n",
    "We then need to define the action to be performed when the alert condition is reached. We can define more than one action for an alert. In our example, in addition to sending an email when the used capacity is more than 5 MB, we can configure Azure Automation to delete the old blobs/files in order to maintain the Azure storage capacity within 5 MB.\n",
    "\n",
    "There are other signals, such as transactions, ingress, egress, availability, Success Server Latency, and Success E2E Latency, on which alerts can be defined. Detailed information on monitoring Azure storage is available at https://docs.microsoft.com/en-us/azure/storage/common/storage-monitoring-diagnosing-troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
